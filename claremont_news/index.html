<!doctype html>
<meta charset="utf-8">
<script src="../template.js"></script>
<script type="text/javascript" async src=img/"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['\\(','\\)']]}
});
</script>

<script type="text/front-matter">
  title: "Editorial Bias in Claremont Student Newspapers"
  publishedDate: 2019-12-05
  description: "I used natural language processing (NLP) algorithms to analyze the five student newspapers of the Claremont Colleges. Highlights of the analysis include that <em>The CMC Forum</em> has the most objective reporting, and that nobody likes to write articles about Harvey Mudd College."
  authors:
  - Mike Izbicki: https://izbicki.me
  affiliations:
  - Mathematical Sciences, Claremont McKenna College: https://cmc.edu/math
</script>

<dt-article>
<h1>Editorial Bias in Claremont Student Newspapers</h1>
<p>
<strong>tl;dr</strong>
I used natural language processing (NLP) algorithms to analyze the five student newspapers of the Claremont Colleges.
Highlights of the analysis include that <em>The CMC Forum</em> has the most objective reporting,
and that nobody likes to write articles about Harvey Mudd College.
</p>

<dt-byline></dt-byline>

<h2>Overview</h2>
<p>
The Claremont Colleges have 5 student newspapers:
<a href=https://tsl.news><em>The Student Life</em></a>,
<a href=https://scrippsvoice.com ><em>The Scripps Voice</em></a>,
<a href=https://www.thegoldenantlers.com ><em>The Golden Antlers</em></a>,
<a href=https://cmcforum.com ><em>The CMC Forum</em></a>,
and
<a href=https://claremontindependent.com ><em>The Claremont Independent</em></a>.
All together, they've published more than ten thousand articles online.
My goal was to understand what types of articles each of these papers publishes.
</p>
<p>
To solve this problem, I first downloaded all the articles from each of these newspapers.
Then I applied five different natural language processing techniques to analyze the dataset:
<a href=#writingstyle>Writing Style Analysis</a>,
<a href=#sentiment>Sentiment Analysis</a>,
<a href=#subjectivity>Subjectivity Analysis</a>,
<a href=#supervised>Supervised Topic Analysis</a>,
and <a href=#unsupervised>Unsupervised Topic Analysis</a>.
Each one of these topics has their own section in the writeup below.

</p>

<a name=data></a>
<h2>The Data</h2>
<p>
I used the <a href='https://github.com/mikeizbicki/NovichenkoBot'>NovichenkoBot</a> web scraper <dt-cite key='izbicki2019novichenkobot'></dt-cite> to download all the articles that the Claremont student newspapers have ever published online.
NovichenkoBot is a tool that I wrote as part of a larger research project for analyzing the bias in online news.
It takes a newspaper's web address as input (e.g. <a href='https://tsl.news'>https://tsl.news</a> for <em>The Student Life</em>),
downloads the newspaper's entire website,
and then extracts all the articles from the website.<dt-fn>The process of extracting articles from a website is surprisingly difficult because not all URLs on a domain correspond to a unique article.  For example, the URL <a href=https://tsl.news/category/life-and-style/>https://tsl.news/category/life-and-style/</a> is not an article for <em>The Student Life</em>, but rather a list of articles.  The NovichenkoBot program is able to identify this fact and does not include the contents of these pages in the list of articles.  The NovichenkoBot is also able to identify ads and other content that is not part of the article's main body of text, and ensures that these extraneous pieces of information are not included in the analysis. </dt-fn>
For each article, the program also outputs lots of metadata like the date that the article was published.
The following plot shows the total number of articles published by Claremont student newspapers in recent years:<dt-fn>
    Several of the newspapers are significantly older than the graphs to the right imply.
    <em>The Student Life</em> has been publishing continuously since 1889, 
    and <em>The Scripps Voice</em> has been publishing continuously since 1998.
    But their webpages only contain more recent articles,
    and this analysis only covers the online articles.
</dt-fn>
</p>
<img class=l-body src=img/articles_per_year.png >
<p>
From this plot, we can easily see that <em>The Student Life</em> is the most active of the student newspapers,
publishing about 2/3rds of all articles.
</p>
<p>
Another interesting trend is that <em>The CMC Forum</em> has been publishing fewer articles every year since 2013.
This is the year that <em>The Claremont Independent</em> was founded,
and so it seems likely that many of the writers who would have otherwise contributed to <em>The Forum</em> are contributing to <em>The Independent</em> instead.
</p>

<a name=writingstyle></a>
<h2>Writing Style Analysis</h2>
<p>
I began my analysis by calculating some simple statistics about the articles each paper publishes.
The following two figures use <a href=https://en.wikipedia.org/wiki/Box_plot>box and whisker plots</a> to show the typical number of words in the titles and bodies of the articles for each paper.
The red bar indicates the median<dt-fn>The "median length" is a better measure than the "average length" of titles/bodies for our purposes because it is less susceptible to outliers.  In particular, it gives us a good idea of the length of a "typical" article we might read from each paper if we picked one at random.</dt-fn> number of words in an article's title or body.
</p>
<img class=l-body src=img/articles_stats_title_words.png >
<img class=l-body src=img/articles_stats_body_words.png  >
<!--<img class=l-body src=img/articles_stats_title_lexicon_count.png >-->
<!--<img class=l-body src=img/articles_stats_body_lexicon_count.png  >-->
<p>
The first thing I noticed about these plots is that <em>The Golden Antlers</em> has the longest titles and the shortest articles.
This makes sense because they are a satire paper,
and the main joke of each article is in the article's click-baity title.
</p>
<p>
I also noticed a similar trend in Claremont's two consortium-wide non-satirical papers.
Compared with <em>The Student Life</em>, <em>The Independent</em> uses fewer words in their titles but has longer stories.
This suggested to me that <em>The Independent</em> is likely to have a more academic and in depth writing style, whereas <em>The Student Life</em> is likely to focus more on traditional journalism.
</p>
<p>
To test this hypothesis, I used Python's <a href=https://pypi.org/project/textstat/>textstat</a> library to calculate the <a href=https://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index>Coleman-Liau Index</a><dt-cite key=coleman1975computer></dt-cite> for each document.
This index estimates the "grade level" that the document is written at.
For example, a document with Coleman-Liau Index 8 would be appropriate for someone who has graduated middle school,
12 would be appropriate for someone who has graduated high school,
and 16 for someone who has graduated college.
</p>
<p>
As before, I plotted the results with a box and whisker plot:

<!--
<dt-fn>
We measured the articles' writing levels using Python's textstat library.
The library includes many other measures of readability.
These measures of readability essentially all agree with the Coleman-Liau Index listed in the main body of the paper,
but they are slightly more difficult to interpret.
For completeness, they are reported below.
<img width=600px src=img/articles_stats_automated_readability_index.png>
<img width=600px src=img/articles_stats_dale_chall_readability_score.png>
<img width=600px src=img/articles_stats_flesch_kincaid_grade.png>
<img width=600px src=img/articles_stats_flesch_reading_ease.png>
<img width=600px src=img/articles_stats_gunning_fog.png>
<img width=600px src=img/articles_stats_linsear_write_formula.png>
<img width=600px src=img/articles_stats_smog_index.png>
<img width=600px src=img/articles_stats_text_standard.png>
</dt-fn>
-->
</p>
<img class=l-body src=img/articles_stats_coleman_liau_index.png >
<p>
We can see that the typical article in <em>The Independent</em> is written at a level roughly 1.5 grades higher than <em>The Student Life</em>,
and more than two grade levels high than the other papers.
</p>
<p>
This advanced reading level is not due to longer or more complex sentences.
As seen below, <em>The Independent</em> and <em>The Student Life</em> have similar sentence lengths,
with <em>The Student Life</em> actually being slightly longer.
</p>
<img class=l-body src=img/articles_stats_body_words_per_body_sentence_count.png >
<p>
Instead, it is due to the use of larger, more difficult words.
The following chart shows the number of rare words<dt-fn>A rare word is defined to be a word that is not in the top ten thousand most commonly used English words.</dt-fn> used per article in each newspaper:
</p>
<img class=l-body src=img/articles_stats_difficult_words.png >
<p>
And the following chart shows the average size of words in each article:
</p>
<img class=l-body src=img/articles_stats_body_syllable_count_per_(1.0*body_words+0.01).png >
<p>
From both of these charts, we can see that <em>The Independent</em> uses rarer, longer words than the other venues,
and this vocabulary choice is what results in their more advanced reading level.
</p>
<p>
This analysis raises two questions:
Is <em>The Independent</em>'s advanced reading level a sign that they are writing better articles that contain more nuanced discussion?
Or is it a sign that they're making obfuscated arguments that are intentionally confusing?
Unfortunately, these are questions that a machine can't answer for us and are up for interpretation.
</p>

<a name=sentiment></a>
<h2>Sentiment Analysis</h2>
<p>
Next, I wanted to understand whether the different papers generally say positive or negative things.
That is, I wanted to analyze the sentiment expressed in the papers.
</p>
<p>
Python's <a href=https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis>textblob</a> <dt-cite key=loria2018textblob></dt-cite> library is a popular tool for sentiment analysis.
It uses a simple algorithm that associates each word in the English language with a score between -1 and +1 (for bad and good sentiments respectively).
For example, the word "evil" has score -1,
the word "newspaper" has score 0,
and the word "happy" has score +1. 
The sentiment of a sentence is then the average sentiment of all its words.
</p>
<p>
Using this tool, I calculated the sentiment for each article's title,
and the results are shown below.
</p>
<img class=l-body src=img/articles_stats_title_polarity.png >
<p>
We can see that <em>The Golden Antlers</em> publish the most positive posts, which makes sense for a satire paper. 
According to textblob, the most positive posts of all time from <em>The Golden Antlers</em> are:
<ol>
    <li><a href='https://www.thegoldenantlers.com/cmc-the-best-god-damn-campus-in-america/'>CMC: The Best God-Damn Campus in America</a></li>
    <li><a href='https://www.thegoldenantlers.com/impressive-first-year-pomona-class-includes-jesus-christ-himself'>Impressive First-Year Pomona Class Includes Jesus Christ himself</a></li>
    <li><a href='https://www.thegoldenantlers.com/princeton-review-rates-claremont-mckenna-2-in-best-sat-scandal'>Princeton Review Rates Claremont McKenna “#2” in “Best SAT Scandal”</a></li>
</ol>
<!--
<p>
And the three most negative:
<ol>
    <li><a href='https://www.thegoldenantlers.com/the-honnold-mudd-library-staff-will-no-longer-be-answering-stupid-ass-questions'>The Honnold-Mudd Library Staff Will No Longer be Answering Stupid Ass Questions</a></li>
    <li><a href='https://www.thegoldenantlers.com/california-faces-worst-drought-in-500-years'>California Faces Worst Drought in 500 Years</a></li>
    <li><a href='https://www.thegoldenantlers.com/tea-time-turns-violent/?snax_login_popup'>Tea Time turns Violent</a></li>
</ol>
</p>
-->
<p>
Of course, these titles are "positive" in only a superficial way and are actually making fun of CMC and Pomona.
But algorithms can't (yet) measure sarcasm.
</p>
<p>
I was more surprised to see that <em>The Scripps Voice</em> has the most negative titles.
So again I looked at the three most negative titles:
<ol>
    <li><a href=http://scrippsvoice.com/sorry-claremont-stag-party-was-disgusting/>Sorry Claremont, Stag Party was Disgusting</a></li>
    <li><a href=http://scrippsvoice.com/women-are-just-bad-at-math-scripps-administration-admits>"Women Are Just Bad at Math" Scripps Administration Admits</a></li>
    <li><a href=http://scrippsvoice.com/shes-just-so-desperate/>“She’s Just So Desperate”</a></li>
</ol>
<p>
What these these articles have in common is that they are criticizing how women are treated and viewed by society.
It definitely makes sense that the newspaper of a women's college would have a lot of negative things to say about how women are treated.
</p>
<!--
<p>
I also repeated the same procedure to calculate the sentiment of each article's body:
</p>
<img class=l-body src=img/articles_stats_body_polarity.png >
<p>
</p>
-->

<a name=subjectivity></a>
<h2>Subjectivity Analysis</h2>
<p>
My next task was to determine how subjective the different newspapers are,
and Python's <a href=https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis>textblob</a> <dt-cite key=loria2018textblob></dt-cite> library also contains a tool for measuring the subjectivity of text.
</p>
<p>
The algorithm works similarly to the sentiment analysis algorithm above.
Each word is given a subjectivity score between 0 and 1,
and then the overall subjectivity of a sentences is the average subjectivity of the component words.
The resulting subjectivity scores are plotted below.
</p>

<!--<img class=l-body src=img/articles_stats_body_subjectivity.png >-->
<img class=l-body src=img/articles_stats_title_subjectivity.png >

<p>
We can see that <em>The Golden Antlers</em> has the most subjective text,
which makes sense because it is a satire paper with over-the-top headlines and articles.
The remaining papers are all relatively objective,<dt-fn>Recall that the red bar in the box and whisker plot indicates a median, so more than half of all articles from <em>The Forum</em>, <em>The Independent</em>, <em>The Scripps Voice</em>, and <em>The Student Life</em> have zero subjectivity (or equivalently 100% objectivity) according to textblob.</dt-fn>
with <em>The Forum</em> being the most objective of them all (but just barely).
</p>

<a name=supervised></a>
<h2>Supervised Topic Analysis</h2>
<p>
My next goal was to learn about *what* the papers are writing about rather than *how* they are writing it.
Data scientists call this procedure <a href=https://en.wikipedia.org/wiki/Topic_model>Topic Analysis</a>,
and it has two forms: supervised and unsupervised.
</p>
<p>
Supervised topic analysis is the simplest version,
and so that's what I started with.
In supervised analysis, we are given a list of topics, and want to know how frequently each newspaper discusses each topic.
For my analysis, I made the list of topics be the five undergraduate Claremont colleges.
I counted the total number of times that articles written in each of the 5 papers mention each of the 5 colleges,<dt-fn>Naively, we can generate these counts with a simple for loop that loops over the entire dataset.  There are two complicating factors, however, that need to be considered.  <br/><br/>First, some of the colleges can be referred to in multiple ways.  For example Claremont McKenna College could be referred to by it's full name, "Claremont McKenna", "McKenna", or "CMC".  The code counted the number of times any of these synonyms was mentioned.<br/><br/>Second, pronouns might sometimes refer to a college, and we want to count these references as well.  Therefore, before looping over the files to perform the count, I performed a procedure called "coreference resolution" that replaces each pronoun in the text with the subject it refers to.  I used the <a href=https://github.com/huggingface/neuralcoref>neuralcoref</a> package to do this substitution.</dt-fn> and plot the results below.
</p>

<img class=l-body src=img/keywords_rate_claremontindependent.com.png >
<img class=l-body src=img/keywords_rate_cmcforum.com.png >
<img class=l-body src=img/keywords_rate_scrippsvoice.com.png >
<img class=l-body src=img/keywords_rate_thegoldenantlers.com.png >
<img class=l-body src=img/keywords_rate_tsl.news.png >

<p>
<em>The CMC Forum</em> and <em>The Scripps Voice</em> mention CMC and Scripps colleges respectively a large number of times, which makes sense because these papers have an explicit editorial mission to focus on these colleges.
</p>
<p>
More surprisingly, <em>The Student Life</em> mentions Pomona college a large number of times, which seems to contradict their stated mission of serving the entire Claremont Consortium equally.
A careful look at the articles written by <em>The Student Life</em> shows that they are particularly inclined to also say more positive things about Pomona College than other colleges.
If we look at the 50 articles with the most positive sentiment from <em>The Student Life</em>, we don't find a single mention of any non-Pomona college by name, but we find many articles like:
</p>
<ol>
    <li><a href=https://tsl.news/news439/>Pomona Named Best Value College Again</a></li>
    <li><a href=https://tsl.news/life-style590/>Pomona Students Bring Their Best Pop Culture Debates to the Blogosphere</a></li>
    <li><a href=https://tsl.news/opinions611/>Vigil Shows Pomona Students at Their Best</a></li>
</ol>
<p>
<em>The Claremont Independent</em> has the most balanced coverage of the Claremont Colleges,
but notably has a distinct lack of reporting about Harvey Mudd.
In fact, Mudd is among the least mentioned colleges for every newspaper.
My hypothesis is that writers for student newspapers are typically humanities majors,
and therefore less interested in reporting about the engineering-focused events that happen on Mudd's campus.
</p>

<!--
<p>Polarities</p>
<img class=l-body src=img/polarities_claremontindependent.com.png >
<img class=l-body src=img/polarities_cmcforum.com.png >
<img class=l-body src=img/polarities_scrippsvoice.com.png >
<img class=l-body src=img/polarities_thegoldenantlers.com.png >
<img class=l-body src=img/polarities_tsl.news.png >

<p>Subjectivities</p>
<img class=l-body src=img/subjectivities_claremontindependent.com.png >
<img class=l-body src=img/subjectivities_cmcforum.com.png >
<img class=l-body src=img/subjectivities_scrippsvoice.com.png >
<img class=l-body src=img/subjectivities_thegoldenantlers.com.png >
<img class=l-body src=img/subjectivities_tsl.news.png >
-->

<a name=unsupervised></a>
<h2>Unsupervised Topic Analysis</h2>

<p>
Unsupervised topic analysis is significantly more complicated than the supervised analysis above.
In the unsupervised version, we are not given a set of topics, but we instead try to figure out automatically what the list of "most discussed" topics are for each paper.
</p>
<p>
There are many algorithms for unsupervised topic analysis,
and they are all significantly more complicated than the algorithms for the previous analyses.
For this project, I used a variant of L1-regularized logistic regression,<dt-fn>
    The unsupervised topic analysis figure was created through a pipeline of machine learning algorithms provided by the <a href=https://scikit-learn.org>scikit-learn</a> library.<dt-cite key=scikit-learn></dt-cite>
First, I created a bag-of-words features from the articles using 3-gram tokens.
Then, I trained a logistic regression model where the class labels were the newspaper that wrote the article.
I needed to use regularization because the number of features (86151) is significantly greater than the number of articles (10305), and I chose L1 regularization because sparse solutions generate nicer visualizations.
The visualization is generated by plotting weight coefficient matrix of the trained logistic regression model.
The final matrix has shape 5x86151, but we only plot the 30 columns with largest L2 norm since these correspond to the 30 words that are most influential in predicting the class label.
Finally, I rearranged the order of the columns (using a co-clustering method) to make the resulting matrix a bit easier to read.
</dt-fn>
but the result of the analysis is shown in the figure below.
</p>

<img class=l-middle-outset src=img/coefs_True_l1_1000.0.png>

<p>
The y-axis of this figure shows the 5 student papers,
and the x-axis shows the 30 most significant topics.
Each box is colored blue if the corresponding topic and newspaper are highly associated with each other (i.e. the newspaper mentions that topic more than other papers);
the box is white if there is no association,
and the box is red if there is negative association
(i.e. the newspaper never mentions that topic).
</p>
<p>
From this figure, we can see that <em>The Forum</em> is associated with photo essays and many topics related to CMC.
Some of their top-rated posts on these topics are:
<ol>
    <li><a href=https://cmcforum.com/2013/opinion/09272013-how-to-successfully-stage-a-protest-at-cmc>How to Successfully Stage a Protest at CMC</a></li>
    <li><a href=https://cmcforum.com/2012/news/09112012-cmc-ranked-tenth-best-college-by-u-s-news>CMC Ranked Tenth Best College By U.S. News</a></li>
    <li><a href=https://cmcforum.com/articles/2018/10/30/art-resources-at-the-5cs>Photo Essay: 5C Art Spots You Wish You Had Known About Earlier</a></li>
    <li><a href=https://cmcforum.com/articles/2018/9/30/toga>Photo Essay: Toga Party 2018</a></li>
</ol>
<p>
We can also see that <em>The Independent</em> is associated with articles on "safe spaces", "blacklivesmatter", and the "lgbtq director".
Looking at their top-rated articles, we see that <em>The Independent</em> tends to criticize these topics:
<ol>
    <li><a href=https://claremontindependent.com/how-blacklivesmatter-failed-black-america/>How #BlackLivesMatter Failed Black America</a></li>
    <li><a href=https://claremontindependent.com/im-wary-white-gays-women-says-new-lgbtq-director/>I’m “Wary of White Gays,” “Women,” Says New LGBTQ Director</a></li>
    <li><a href=https://claremontindependent.com/safe-spaces-where-free-press-dies/>Safe Spaces: Where Free Press Dies</a></li>
</ol>
<!--<em>The Golden Antlers</em> is associated with the highly sophisticated topics of "fuck" and "bros";-->
<!--and -->
<!--</p>-->
<p>
The figure above shows few topics from <em>The Scripps Voice</em> or <em>The Student Life</em>.
This is because I only plotted the top 50 topics (so that they would all fit on the screen).
If I has plotted more topics, then we would have seen more topics related to these two papers.
</p>

<!--
<p>
<a href=https://claremontindependent.com/cmc-funds-racially-exclusive-program-to-fight-racism/>CMC Funds Racially Exclusive Program to Fight Racism</a>

<a href=https://claremontindependent.com/pomona-progressives-create-whites-only-club-to-fight-racism/>Pomona Progressives Create Whites-Only Club to Fight Racism</a>
</p>
-->

<a name=conclusion></a>
<h2>Conclusion</h2>

<p>
Each of the Claremont newspapers has its niche,
and in this article I used some simple data mining techniques to help me better understand what those niches are,
and to find representative articles about those niches.
</p>
<p>
These analyses are just scratching the surface of what modern natural language processing techniques can do.
If these types of analysis are interesting to you,
you should consider taking CMC's <a href=https://catalog.claremontmckenna.edu/preview_program.php?catoid=23&poid=1739>data science sequence</a>.
This sequence of courses will teach you state-of-the-art natural language processing techniques and how to apply them to a wide variety of application domains.
If you have any questions, feel free to reach out to me at <a href=mailto:mizbicki@cmc.edu>mizbicki@cmc.edu</a>.
</p>

</dt-article>

<dt-appendix>
</dt-appendix>

<script type="text/bibliography">
@article{izbicki2019novichenkobot,
  title={NovichenkoBot: A Webscraper for Downloading Newspaper Articles},
  author={Mike Izbicki},
  year={2019},
}

@article{coleman1975computer,
  title={A computer readability formula designed for machine scoring.},
  author={Coleman, Meri and Liau, Ta Lin},
  journal={Journal of Applied Psychology},
  volume={60},
  number={2},
  pages={283},
  year={1975},
  publisher={American Psychological Association}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in Python},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@techreport{loria2018textblob,
  title={textblob Documentation},
  author={Loria, Steven},
  year={2018}
}
</script>
